{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<H1 align=\"middle\">Long Short-Term Memory for Membership Inference Attack on Beacon Data</H1>\n",
    "\n",
    "<br>\n",
    "<strong>This notebook performs random search-based hyperparameter optimization for long short-term memory-based membership inference attacks on Beacon data.</strong>"
   ],
   "id": "988b0724d136f87d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "998de440c0ddfa0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Python Libraries",
   "id": "91e68603d868fb39"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import gc\n",
    "import random\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### External Libraries",
   "id": "1f66ddfdd3fc2512"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn"
   ],
   "id": "7edabca34dd9fec6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Custom Libraries",
   "id": "e2e036d5386dc5f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils_random import set_random_seed\n",
    "from src.utils_torch.data import stratified_random_split\n",
    "from src.utils_attacker_lstm.data import DatasetAttackerLSTMBeacon, DataLoaderAttackerLSTM\n",
    "from src.utils_attacker_lstm.models import ModelAttackerLSTM, TesterAttackerLSTM, TrainerAttackerLSTM, \\\n",
    "    ManagerAttackerLSTM\n",
    "from src.utils_plot import plot_train_eval_loss_accuracy, plot_receiver_operating_characteristics_curve, \\\n",
    "    plot_confusion_matrix, plot_long_short_term_memory\n",
    "from src.utils_torch.modules import get_seq_size_out"
   ],
   "id": "50e8c25c7f3b4ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Search",
   "id": "991fc7df461ccb04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "idx = 0\n",
    "while True:\n",
    "    try:\n",
    "        model_id = datetime.now().strftime(\"%m%d%H%M\")\n",
    "        print(\"=\" * 25)\n",
    "        print(f\"Model {idx}\")\n",
    "        print(f\"Model ID: {model_id}\")\n",
    "        random_seed = random.randint(0, 2 ** 32 - 1)\n",
    "        set_random_seed(random_seed)\n",
    "        num_snps = random.choice([10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000])\n",
    "        train_eval_test_split = [0.7, 0.15, 0.15]\n",
    "        genome_batch_size = random.randint(16, 64)\n",
    "        snp_batch_size = num_snps\n",
    "        found = False\n",
    "        while not found:\n",
    "            conv_num_layers = random.randint(1, 8)\n",
    "            conv_channel_size = [3] + [random.randint(16, 64) for _ in range(conv_num_layers)]\n",
    "            conv_kernel_size = [random.randint(4, 32) for _ in range(conv_num_layers)]\n",
    "            conv_stride = [random.randint(1, conv_kernel_size[i]) for i in range(conv_num_layers)]\n",
    "            conv_dilation = [random.randint(1, 4) for _ in range(conv_num_layers)]\n",
    "            conv_groups = [1 for _ in range(conv_num_layers)]\n",
    "            found = True\n",
    "            sequence_size = num_snps\n",
    "            for i in range(conv_num_layers):\n",
    "                sequence_size = get_seq_size_out(seq_size_in=sequence_size,\n",
    "                                                 kernel_size=conv_kernel_size[i],\n",
    "                                                 stride=conv_stride[i],\n",
    "                                                 padding=0,\n",
    "                                                 dilation=conv_dilation[i])\n",
    "                if sequence_size < conv_kernel_size[i]:\n",
    "                    found = False\n",
    "                    break\n",
    "        conv_activation = random.choice([nn.ReLU, nn.Tanh, nn.Sigmoid, nn.LeakyReLU])\n",
    "        conv_activation_kwargs = {}\n",
    "        conv_dropout_p = [random.uniform(0, 0.66) for _ in range(conv_num_layers - 1)]\n",
    "        conv_dropout_first = [random.choice([True, False]) for _ in range(conv_num_layers - 1)]\n",
    "        conv_batch_norm = [random.choice([True, False]) for _ in range(conv_num_layers - 1)]\n",
    "        conv_batch_norm_momentum = [random.uniform(0, 1) for _ in range(conv_num_layers - 1)]\n",
    "        conv_lstm_activation = random.choice([nn.ReLU, nn.Tanh, nn.Sigmoid, nn.LeakyReLU])\n",
    "        conv_lstm_activation_kwargs = {}\n",
    "        conv_lstm_dropout_p = random.uniform(0, 0.66)\n",
    "        conv_lstm_dropout_first = random.choice([True, False])\n",
    "        conv_lstm_layer_norm = random.choice([True, False])\n",
    "        lstm_num_layers = random.randint(1, 4)\n",
    "        lstm_input_size = conv_channel_size[-1]\n",
    "        lstm_hidden_size = [random.randint(4, 64) for _ in range(lstm_num_layers)]\n",
    "        lstm_proj_size = [0 for _ in range(lstm_num_layers)]\n",
    "        lstm_bidirectional = [random.choice([True, False]) for _ in range(lstm_num_layers)]\n",
    "        lstm_dropout_p = [random.uniform(0, 0.66) for _ in range(lstm_num_layers - 1)]\n",
    "        lstm_dropout_first = [random.choice([True, False]) for _ in range(lstm_num_layers - 1)]\n",
    "        lstm_layer_norm = [random.choice([True, False]) for _ in range(lstm_num_layers - 1)]\n",
    "        lstm_linear_dropout_p = random.uniform(0, 0.66)\n",
    "        lstm_linear_dropout_first = random.choice([True, False])\n",
    "        lstm_linear_batch_norm = random.choice([True, False])\n",
    "        lstm_linear_batch_norm_momentum = random.uniform(0, 1)\n",
    "        linear_num_layers = random.randint(1, 4)\n",
    "        linear_num_features = [lstm_hidden_size[-1] * (2 if any(lstm_bidirectional) else 1)] + [random.randint(4, 64)\n",
    "                                                                                                for _\n",
    "                                                                                                in range(\n",
    "                linear_num_layers - 1)] + [1]\n",
    "        linear_activation = random.choice([nn.ReLU, nn.Tanh, nn.Sigmoid, nn.LeakyReLU])\n",
    "        linear_activation_kwargs = {}\n",
    "        linear_dropout_p = [random.uniform(0, 0.66) for _ in range(linear_num_layers - 1)]\n",
    "        linear_dropout_first = [random.choice([True, False]) for _ in range(linear_num_layers - 1)]\n",
    "        linear_batch_norm = [random.choice([True, False]) for _ in range(linear_num_layers - 1)]\n",
    "        linear_batch_norm_momentum = [random.uniform(0, 1) for _ in range(linear_num_layers - 1)]\n",
    "        num_epochs = 256\n",
    "        learning_rate = 0.001\n",
    "        models_dir = \"../models\"\n",
    "        models_file = \"models.csv\"\n",
    "        plots_dir = \"../plots\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device('mps')\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        dataset = DatasetAttackerLSTMBeacon(genomes_beacon_path=\"../data/idash/In_Pop.pkl\",\n",
    "                                            genomes_reference_path=\"../data/idash/Not_In_Pop.pkl\",\n",
    "                                            num_snps=num_snps)\n",
    "        subset_train, subset_eval, subset_test = stratified_random_split(dataset=dataset,\n",
    "                                                                         ratios=train_eval_test_split)\n",
    "        dataloader_train = DataLoaderAttackerLSTM(dataset=subset_train,\n",
    "                                                  genome_batch_size=genome_batch_size,\n",
    "                                                  snp_batch_size=snp_batch_size,\n",
    "                                                  shuffle=True)\n",
    "        dataloader_eval = DataLoaderAttackerLSTM(dataset=subset_eval,\n",
    "                                                 genome_batch_size=genome_batch_size,\n",
    "                                                 snp_batch_size=snp_batch_size,\n",
    "                                                 shuffle=False)\n",
    "        dataloader_test = DataLoaderAttackerLSTM(dataset=subset_test,\n",
    "                                                 genome_batch_size=genome_batch_size,\n",
    "                                                 snp_batch_size=snp_batch_size,\n",
    "                                                 shuffle=False)\n",
    "        model = ModelAttackerLSTM(conv_num_layers=conv_num_layers,\n",
    "                                  conv_channel_size=conv_channel_size,\n",
    "                                  conv_kernel_size=conv_kernel_size,\n",
    "                                  conv_stride=conv_stride,\n",
    "                                  conv_dilation=conv_dilation,\n",
    "                                  conv_groups=conv_groups,\n",
    "                                  conv_activation=conv_activation,\n",
    "                                  conv_activation_kwargs=conv_activation_kwargs,\n",
    "                                  conv_dropout_p=conv_dropout_p,\n",
    "                                  conv_dropout_first=conv_dropout_first,\n",
    "                                  conv_batch_norm=conv_batch_norm,\n",
    "                                  conv_batch_norm_momentum=conv_batch_norm_momentum,\n",
    "                                  conv_lstm_activation=conv_lstm_activation,\n",
    "                                  conv_lstm_activation_kwargs=conv_lstm_activation_kwargs,\n",
    "                                  conv_lstm_dropout_p=conv_lstm_dropout_p,\n",
    "                                  conv_lstm_dropout_first=conv_lstm_dropout_first,\n",
    "                                  conv_lstm_layer_norm=conv_lstm_layer_norm,\n",
    "                                  lstm_num_layers=lstm_num_layers,\n",
    "                                  lstm_input_size=lstm_input_size,\n",
    "                                  lstm_hidden_size=lstm_hidden_size,\n",
    "                                  lstm_proj_size=lstm_proj_size,\n",
    "                                  lstm_bidirectional=lstm_bidirectional,\n",
    "                                  lstm_dropout_p=lstm_dropout_p,\n",
    "                                  lstm_dropout_first=lstm_dropout_first,\n",
    "                                  lstm_layer_norm=lstm_layer_norm,\n",
    "                                  lstm_linear_dropout_p=lstm_linear_dropout_p,\n",
    "                                  lstm_linear_dropout_first=lstm_linear_dropout_first,\n",
    "                                  lstm_linear_batch_norm=lstm_linear_batch_norm,\n",
    "                                  lstm_linear_batch_norm_momentum=lstm_linear_batch_norm_momentum,\n",
    "                                  linear_num_layers=linear_num_layers,\n",
    "                                  linear_num_features=linear_num_features,\n",
    "                                  linear_activation=linear_activation,\n",
    "                                  linear_activation_kwargs=linear_activation_kwargs,\n",
    "                                  linear_dropout_p=linear_dropout_p,\n",
    "                                  linear_dropout_first=linear_dropout_first,\n",
    "                                  linear_batch_norm=linear_batch_norm,\n",
    "                                  linear_batch_norm_momentum=linear_batch_norm_momentum)\n",
    "        model.to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                     lr=learning_rate)\n",
    "        scheduler = None\n",
    "        trainer = TrainerAttackerLSTM(model=model,\n",
    "                                      criterion=criterion,\n",
    "                                      optimizer=optimizer,\n",
    "                                      scheduler=scheduler,\n",
    "                                      train_loader=dataloader_train,\n",
    "                                      eval_loader=dataloader_eval,\n",
    "                                      device=device,\n",
    "                                      max_grad_norm=1.0,\n",
    "                                      norm_type=2)\n",
    "        tester = TesterAttackerLSTM(model=model,\n",
    "                                    criterion=criterion,\n",
    "                                    test_loader=dataloader_test,\n",
    "                                    device=device)\n",
    "        manager = ManagerAttackerLSTM(models_dir=models_dir,\n",
    "                                      models_file=models_file)\n",
    "        trainer.train(num_epochs=num_epochs,\n",
    "                      verbose=False)\n",
    "        finish_time = datetime.now()\n",
    "        best_eval_loss_epoch = trainer.best_eval_loss_epoch\n",
    "        best_eval_loss = trainer.best_eval_loss\n",
    "        best_eval_accuracy = trainer.eval_accuracies[best_eval_loss_epoch]\n",
    "        # print(f'Finished training at {finish_time}')\n",
    "        print(f'Best evaluation loss epoch found at: {best_eval_loss_epoch}')\n",
    "        print(f'Best evaluation loss found: {best_eval_loss:.4f}')\n",
    "        print(f'Best evaluation accuracy found: {best_eval_accuracy:.4f}')\n",
    "        plot_train_eval_loss_accuracy(train_loss=trainer.train_losses,\n",
    "                                      train_accuracy=trainer.train_accuracies,\n",
    "                                      eval_loss=trainer.eval_losses,\n",
    "                                      eval_accuracy=trainer.eval_accuracies,\n",
    "                                      saved_epoch=best_eval_loss_epoch,\n",
    "                                      output_path=plots_dir,\n",
    "                                      output_file=f\"model_attacker_beacon_{model_id}_train_eval_loss_acc.png\",\n",
    "                                      show=False)\n",
    "        tester.test()\n",
    "        print(f'Test loss: {tester.loss:.4f}')\n",
    "        print(f'Test accuracy: {tester.accuracy_score:.2f}')\n",
    "        print(f'Test precision: {tester.precision_score:.2f}')\n",
    "        print(f'Test recall: {tester.recall_score:.2f}')\n",
    "        print(f'Test f1: {tester.f1_score:.2f}')\n",
    "        print(f'Test AUC: {tester.auroc_score:.2f}')\n",
    "        fpr, tpr, _ = tester.roc_curve\n",
    "        plot_receiver_operating_characteristics_curve(false_positive_rates=fpr,\n",
    "                                                      true_positive_rates=tpr,\n",
    "                                                      auc=tester.auroc_score,\n",
    "                                                      output_path=plots_dir,\n",
    "                                                      output_file=f\"model_attacker_beacon_{model_id}_roc_curve.png\",\n",
    "                                                      show=False)\n",
    "        plot_confusion_matrix(confusion_matrix=tester.confusion_matrix_scores,\n",
    "                              task=\"binary\",\n",
    "                              output_path=plots_dir,\n",
    "                              output_file=f\"model_attacker_beacon_{model_id}_confusion_matrix.png\",\n",
    "                              show=False)\n",
    "        manager.add_model(model_id=model_id,\n",
    "                          random_seed=random_seed,\n",
    "                          data=dataset,\n",
    "                          loader=dataloader_train,\n",
    "                          model=model,\n",
    "                          trainer=trainer,\n",
    "                          tester=tester)\n",
    "        model.set_hidden_cell_mode(True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x, y = dataloader_test.dataset[0]\n",
    "            x = x.unsqueeze(0).to(device)\n",
    "            hx = None\n",
    "            logits, out = model.forward(x, hx)\n",
    "        out_last = out[-1]\n",
    "        (h, c), (h_last, c_last) = out_last\n",
    "        h, c = h.squeeze(0), c.squeeze(0)\n",
    "        plot_long_short_term_memory(long_term_memory=c.cpu(),\n",
    "                                    short_term_memory=h.cpu(),\n",
    "                                    bidirectional=lstm_bidirectional[-1],\n",
    "                                    output_path=plots_dir,\n",
    "                                    output_file=f\"model_attacker_beacon_{model_id}_lstm.png\",\n",
    "                                    show=False)\n",
    "        idx += 1\n",
    "        model.cpu()\n",
    "        del model, criterion, optimizer, scheduler, trainer, tester, manager\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ],
   "id": "efd1ea7e0dbc5193",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
